{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict\n",
    "\n",
    "# Initialize wandb\n",
    "api = wandb.Api()\n",
    "\n",
    "# Get runs from your project\n",
    "runs = api.runs(\"go-embedding-evaluation\")  # Replace with your actual project name\n",
    "runs = [(run.config, run.history()) for run in runs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Create summary table\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m summary_table \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpivot_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbase_ontology\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membedding_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmetric\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlast\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     42\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Display the table\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDetailed Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/p/research/contempro/owl2vec_star/.pixi/envs/default/lib/python3.9/site-packages/pandas/core/frame.py:9509\u001b[0m, in \u001b[0;36mpivot_table\u001b[0;34m(self, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n",
      "File \u001b[0;32m~/p/research/contempro/owl2vec_star/.pixi/envs/default/lib/python3.9/site-packages/pandas/core/reshape/pivot.py:102\u001b[0m, in \u001b[0;36mpivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n",
      "File \u001b[0;32m~/p/research/contempro/owl2vec_star/.pixi/envs/default/lib/python3.9/site-packages/pandas/core/reshape/pivot.py:148\u001b[0m, in \u001b[0;36m__internal_pivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'value'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Collect data\n",
    "data = []\n",
    "for config, history in runs:\n",
    "    # Get the last logged metrics\n",
    "    if not history.empty:\n",
    "        # Extract metrics for each embedding type and model\n",
    "        for _, metrics in history.iterrows():\n",
    "            metrics_dict = metrics.to_dict()\n",
    "            for key, value in metrics_dict.items():\n",
    "                if isinstance(value, (int, float)):  # Filter out non-numeric values\n",
    "                    # Parse the metric key (format: \"embedding_type/model/metric\")\n",
    "                    parts = key.split('/')\n",
    "                    # if len(parts) == 3:\n",
    "                    #     embedding_type, model, metric = parts\n",
    "                    #     if model == 'torch_mlp' and metric in [\"MRR\", \"Hits@1\", \"Hits@3\", \"Hits@10\"]:\n",
    "                    #         data.append({\n",
    "                    #             'base_ontology': config.get('base_ontology', 'unknown'),\n",
    "                    #             'embedding_type': embedding_type,\n",
    "                    #             'model': model,\n",
    "                    #             'metric': metric,\n",
    "                    #             'value': value\n",
    "                    #         })\n",
    "                    if len(parts) == 4:\n",
    "                        base_ontology, embedding_type, model, metric = parts\n",
    "                        if model == 'torch_mlp' and metric in [\"MRR\", \"Hits@1\", \"Hits@3\", \"Hits@10\"]:\n",
    "                            data.append({\n",
    "                                'base_ontology': config.get('base_ontology', 'unknown'),\n",
    "                                'embedding_type': embedding_type,\n",
    "                                'model': model,\n",
    "                                'metric': metric,\n",
    "                                'value': value\n",
    "                            })\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create summary table\n",
    "summary_table = df.pivot_table(\n",
    "    index=['base_ontology', 'embedding_type', 'model'],\n",
    "    columns='metric',\n",
    "    values='value',\n",
    "    aggfunc='last'\n",
    ").round(3)\n",
    "\n",
    "# Display the table\n",
    "print(\"\\nDetailed Results:\")\n",
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.73 ms ± 98.6 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "6.07 ms ± 473 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "randvec = np.random.randn(768)\n",
    "%timeit np.repeat(np.expand_dims(randvec, 0), 10000, axis=0)\n",
    "%timeit np.array([randvec] * 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328 μs ± 2.2 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "43.9 μs ± 2.49 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numba\n",
    "import numpy as np\n",
    "from numba import typed\n",
    "\n",
    "# Sample data setup\n",
    "all_classes = np.random.randint(0, 10000, 10000)\n",
    "\n",
    "@numba.njit\n",
    "def filter_classes(all_classes, ancestors):\n",
    "    \"\"\"\n",
    "    Create a boolean mask for filtering classes\n",
    "\n",
    "    Args:\n",
    "        all_classes: Array of all class IDs\n",
    "        ancestors: Array of ancestor class IDs to filter out\n",
    "\n",
    "    Returns:\n",
    "        Boolean mask where True indicates class should be kept\n",
    "    \"\"\"\n",
    "    mask = np.ones(len(all_classes), dtype=numba.bool_)\n",
    "\n",
    "    # Numba-friendly loop for checking membership\n",
    "    for i in range(len(all_classes)):\n",
    "        for j in range(len(ancestors)):\n",
    "            if all_classes[i] == ancestors[j]:\n",
    "                mask[i] = False\n",
    "                break\n",
    "    return mask\n",
    "\n",
    "def numpy_filter(all_classes, ancestors):\n",
    "    \"\"\"\n",
    "    NumPy version for comparison\n",
    "    \"\"\"\n",
    "    return ~np.isin(all_classes, ancestors)\n",
    "\n",
    "# Setup test data\n",
    "sub_id = 100\n",
    "ancestors = np.random.randint(0, 10000, 100)\n",
    "\n",
    "# Benchmark\n",
    "%timeit filter_classes(all_classes, ancestors)\n",
    "%timeit numpy_filter(all_classes, ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 51\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# %timeit calculate_metrics(gt_id, valid_classes, sorted_indices)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# %timeit calculate_metrics_2(gt_id, valid_classes, sorted_indices)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# %timeit numpy_calculate_metrics(gt_id, valid_classes, sorted_indices)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m valid_classes:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(calculate_metrics(\u001b[38;5;28mcls\u001b[39m, valid_classes, sorted_indices), calculate_metrics_2(\u001b[38;5;28mcls\u001b[39m, valid_classes, sorted_indices))\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(calculate_metrics(\u001b[38;5;28mcls\u001b[39m, valid_classes, sorted_indices), numpy_calculate_metrics(\u001b[38;5;28mcls\u001b[39m, valid_classes, sorted_indices))\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from re import A\n",
    "\n",
    "\n",
    "valid_classes = np.random.randint(0, 10000, 1000)\n",
    "gt_id = valid_classes[0]\n",
    "sorted_indices = np.argsort(valid_classes)[::-1]\n",
    "\n",
    "@numba.njit()\n",
    "def calculate_metrics(gt_id, valid_classes, sorted_indices):\n",
    "    # Find rank of ground truth\n",
    "    gt_rank = np.where(valid_classes[sorted_indices] == gt_id)[0][0] + 1\n",
    "\n",
    "    # Calculate hits metrics\n",
    "    hits1 = gt_id == valid_classes[sorted_indices[0]]\n",
    "    hits5 = gt_id in valid_classes[sorted_indices[:5]]\n",
    "    hits10 = gt_id in valid_classes[sorted_indices[:10]]\n",
    "\n",
    "    return 1.0/gt_rank, hits1, hits5, hits10\n",
    "\n",
    "def numpy_calculate_metrics(gt_id, valid_classes, sorted_indices):\n",
    "    # Find rank of ground truth\n",
    "    gt_rank = np.where(valid_classes[sorted_indices] == gt_id)[0][0] + 1\n",
    "    return 1.0/gt_rank, gt_id == valid_classes[sorted_indices[0]], gt_id in valid_classes[sorted_indices[:5]], gt_id in valid_classes[sorted_indices[:10]]\n",
    "\n",
    "@numba.njit()\n",
    "def calculate_metrics_2(gt_id, valid_classes, sorted_indices):\n",
    "    # Find position of ground truth in valid_classes\n",
    "    gt_pos = -1\n",
    "    for i, idx in enumerate(sorted_indices):\n",
    "        if valid_classes[idx] == gt_id:\n",
    "            gt_pos = i\n",
    "            break\n",
    "\n",
    "    if gt_pos == -1:\n",
    "        return 0.0, False, False, False\n",
    "\n",
    "    # Calculate metrics\n",
    "    gt_rank = gt_pos + 1\n",
    "    hits1 = gt_pos == 0\n",
    "    hits5 = gt_pos < 5\n",
    "    hits10 = gt_pos < 10\n",
    "\n",
    "    return 1.0/gt_rank, hits1, hits5, hits10\n",
    "\n",
    "\n",
    "# %timeit calculate_metrics(gt_id, valid_classes, sorted_indices)\n",
    "# %timeit calculate_metrics_2(gt_id, valid_classes, sorted_indices)\n",
    "# %timeit numpy_calculate_metrics(gt_id, valid_classes, sorted_indices)\n",
    "\n",
    "for cls in valid_classes:\n",
    "    assert np.allclose(calculate_metrics(cls, valid_classes, sorted_indices), calculate_metrics_2(cls, valid_classes, sorted_indices))\n",
    "    assert np.allclose(calculate_metrics(cls, valid_classes, sorted_indices), numpy_calculate_metrics(cls, valid_classes, sorted_indices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.21 s ± 138 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "105 ms ± 2.63 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "@numba.njit(parallel=True)\n",
    "def prep_input(sub_v, all_class_v, input_type):\n",
    "    if input_type == 'concatenate':\n",
    "        # Create repeated sub_v array\n",
    "        repeated_sub = np.empty((len(all_class_v), len(sub_v) * 2))\n",
    "        for i in range(len(all_class_v)):\n",
    "            repeated_sub[i, :len(sub_v)] = sub_v\n",
    "            repeated_sub[i, len(sub_v):] = all_class_v[i]\n",
    "\n",
    "        return repeated_sub\n",
    "    else:\n",
    "        # Create repeated sub_v array and subtract\n",
    "        repeated_sub = np.empty((len(all_class_v), len(sub_v)))\n",
    "        for i in range(len(all_class_v)):\n",
    "            repeated_sub[i] = sub_v\n",
    "        return repeated_sub - all_class_v\n",
    "\n",
    "def numpy_prep_input(sub_v, all_class_v, input_type):\n",
    "    if input_type == 'concatenate':\n",
    "        return np.concatenate([np.repeat(sub_v[None, :], len(all_class_v), axis=0), all_class_v], axis=1)\n",
    "    else:\n",
    "        return np.repeat(sub_v[None, :], len(all_class_v), axis=0) - all_class_v\n",
    "\n",
    "sub_v = np.random.randn(768)\n",
    "all_class_v = np.random.randn(40000, 768)\n",
    "input_type = 'concatenate'\n",
    "\n",
    "%timeit prep_input(sub_v, all_class_v, input_type)\n",
    "%timeit numpy_prep_input(sub_v, all_class_v, input_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
